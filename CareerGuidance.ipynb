{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTrWM_mMWoBy",
        "outputId": "9ed8244b-6a03-47be-9d24-044cea07731d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available: True\n",
            "CUDA Device Count: 1\n",
            "CUDA Device Name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
        "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8Bt6PJYtdwk",
        "outputId": "c4691599-3ff6-4264-9b01-3df13e179c0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-huggingface in c:\\users\\ayush\\anaconda3\\lib\\site-packages (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-llms-huggingface) (0.30.2)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-llms-huggingface) (0.12.30)\n",
            "Requirement already satisfied: text-generation<0.8.0,>=0.7.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-llms-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.51.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (6.0.1)\n",
            "Requirement already satisfied: requests in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface) (4.13.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.10.5)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.0.0)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.0)\n",
            "Requirement already satisfied: httpx in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.9.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.14.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.6)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (78.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.5.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.11.0)\n",
            "Requirement already satisfied: griffe in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.7.0)\n",
            "Requirement already satisfied: click in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.0.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->llama-index-llms-huggingface) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.26.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (4.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
        "!pip install sentence_transformers -q\n",
        "!pip install llama_index -q\n",
        "%pip install llama-index-llms-huggingface\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HDYPb8C7jZKw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:161: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader,ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "G66zjM5rjn-R",
        "outputId": "1dedcd62-3ac3-431a-aa64-65a320a2e975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 766 ms\n",
            "Wall time: 1.05 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "documents = SimpleDirectoryReader(\"./data/scraped\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "eNiMsmzkj2qT",
        "outputId": "fa3ed1fb-ed6f-4ff1-9cf2-48a6e8d9160f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1011,\n",
              " Document(id_='e0aa2400-a06b-401c-bb87-2a9380d7efef', embedding=None, metadata={'file_path': 'c:\\\\Users\\\\Public\\\\ML-Career Guidance Chatbot\\\\data\\\\scraped\\\\Biofuels or Biodiesel Technology and Product Development Managers.txt', 'file_name': 'Biofuels or Biodiesel Technology and Product Development Managers.txt', 'file_type': 'text/plain', 'file_size': 16606, 'creation_date': '2025-03-31', 'last_modified_date': '2025-03-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"  Careers / Biofuels/Biodiesel Technology and Product Development Managers  \\r\\n        Summary Description\\r\\nDefine, plan, or execute biofuels/biodiesel research programs that evaluate alternative feedstock and process technologies with near-term commercial potential.\\r\\n  Sample Job Titles\\r\\n1.\\r\\nAnalytical Research Program Manager\\r\\n2.\\r\\nBiodiesel Division Manager\\r\\n3.\\r\\nBiodiesel Engineering Manager\\r\\n4.\\r\\nBiodiesel Product Development Manager\\r\\n5.\\r\\nBiodiesel Product Manager\\r\\n6.\\r\\nBiodiesel Technology Development Manager\\r\\n7.\\r\\nBiodiesel Technology Manager\\r\\n8.\\r\\nBiofuels Engineering Manager\\r\\n9.\\r\\nBiofuels Manager\\r\\n10.\\r\\nBiofuels Product Development Manager\\r\\n11.\\r\\nBiofuels Product Manager\\r\\n12.\\r\\nBiofuels Research Scientist\\r\\n13.\\r\\nBiofuels Technology Development Manager\\r\\n14.\\r\\nBiofuels Technology Manager\\r\\n  15.\\r\\nChief Technology Officer (CTO)\\r\\n16.\\r\\nFermentation Manager\\r\\n17.\\r\\nFermentation Scientist\\r\\n18.\\r\\nLaboratory Manager (Lab Manager)\\r\\n19.\\r\\nManager of Business Development and New Technology\\r\\n20.\\r\\nProduct Applications Scientist\\r\\n21.\\r\\nProduct Scientist\\r\\n22.\\r\\nProject Development Director\\r\\n23.\\r\\nResearch Associate\\r\\n24.\\r\\nScientist\\r\\n25.\\r\\nSenior Research Associate\\r\\n26.\\r\\nSenior Research Scientist\\r\\n27.\\r\\nSeparations Scientist\\r\\n  Job Tasks\\r\\nDesign or conduct applied biodiesel or biofuels research projects on topics such as transport, thermodynamics, mixing, filtration, distillation, fermentation, extraction, and separation.\\r\\nDevelop technical processes to improve the efficiency of biofuel production.\\r\\nAnalyze data from biofuels studies, such as fluid dynamics, water treatments, or solvent extraction and recovery processes.\\r\\nEvaluate energy production data.\\r\\nPrepare, or oversee the preparation of, experimental plans for biofuels research or development.\\r\\nDevelop operating strategies, plans, or procedures for green or sustainable operations.\\r\\nProvide technical or scientific guidance to technical staff in the conduct of biofuels research or development.\\r\\nSupervise workers performing environmentally sustainable activities.\\r\\nPropose new biofuels products, processes, technologies or applications based on findings from applied biofuels or biomass research projects.\\r\\nDevelop specifications for new products or processes.\\r\\nConduct experiments on biomass or pretreatment technologies.\\r\\nTest green technologies or processes.\\r\\nPrepare biofuels research and development reports for senior management or technical professionals.\\r\\nCommunicate green energy production information.\\r\\nDevelop lab scale models of industrial scale processes, such as fermentation.\\r\\nModel operational processes.\\r\\nOversee biodiesel/biofuels prototyping or development projects.\\r\\nDirect green energy production operations.\\r\\nDevelop methods to estimate the efficiency of biomass pretreatments.\\r\\nDevelop technical processes to improve the efficiency of biofuel production.\\r\\nConduct experiments to test new or alternate feedstock fermentation processes.\\r\\nTest green technologies or processes.\\r\\nDevelop carbohydrates arrays and associated methods for screening enzymes involved in biomass conversion.\\r\\nDevelop technical processes to improve the efficiency of biofuel production.\\r\\nPerform protein functional analysis and engineering for processing of feedstock and creation of biofuels.\\r\\nTest green technologies or processes.\\r\\nConduct research to breed or develop energy crops with improved biomass yield, environmental adaptability, pest resistance, production efficiency, bioprocessing characteristics, or reduced environmental impacts.\\r\\nTest green technologies or processes.\\r\\nDevelop computational tools or approaches to improve biofuels research and development activities.\\r\\nDevelop technical processes to improve the efficiency of biofuel production.\\r\\nDevelop separation processes to recover biofuels.\\r\\nDevelop technical processes to improve the efficiency of biofuel production.\\r\\nDesign chemical conversion processes, such as etherification, esterification, interesterification, transesterification, distillation, hydrogenation, oxidation or reduction of fats and oils, and vegetable oil refining.\\r\\nDevelop technical processes to improve the efficiency of biofuel production.\\r\\nDesign or execute solvent or product recovery experiments in laboratory or field settings.\\r\\nDevelop technical processes to improve the efficiency of biofuel production.\\r\\nDevelop methods to recover ethanol or other fuels from complex bioreactor liquid and gas streams.\\r\\nDevelop technical processes to improve the efficiency of biofuel production.\\r\\n  Work Activities\\r\\nImportance Work Activity\\r\\n90\\r\\nInteracting With Computers — Using computers and computer systems (including hardware and software) to program, write software, set up functions, enter data, or process information.\\r\\n89\\r\\nMaking Decisions and Solving Problems — Analyzing information and evaluating results to choose the best solution and solve problems.\\r\\n88\\r\\nAnalyzing Data or Information — Identifying the underlying principles, reasons, or facts of information by breaking down information or data into separate parts.\\r\\n87\\r\\nGetting Information — Observing, receiving, and otherwise obtaining information from all relevant sources.\\r\\n83\\r\\nProcessing Information — Compiling, coding, categorizing, calculating, tabulating, auditing, or verifying information or data.\\r\\n82\\r\\nCommunicating with Supervisors, Peers, or Subordinates — Providing information to supervisors, co-workers, and subordinates by telephone, in written form, e-mail, or in person.\\r\\n77\\r\\nUpdating and Using Relevant Knowledge — Keeping up-to-date technically and applying new knowledge to your job.\\r\\n77\\r\\nMonitor Processes, Materials, or Surroundings — Monitoring and reviewing information from materials, events, or the environment, to detect or assess problems.\\r\\n77\\r\\nDeveloping and Building Teams — Encouraging and building mutual trust, respect, and cooperation among team members.\\r\\n76\\r\\nIdentifying Objects, Actions, and Events — Identifying information by categorizing, estimating, recognizing differences or similarities, and detecting changes in circumstances or events.\\r\\n76\\r\\nThinking Creatively — Developing, designing, or creating new applications, ideas, relationships, systems, or products, including artistic contributions.\\r\\n76\\r\\nDeveloping Objectives and Strategies — Establishing long-range objectives and specifying the strategies and actions to achieve them.\\r\\n75\\r\\nDocumenting/Recording Information — Entering, transcribing, recording, storing, or maintaining information in written or electronic/magnetic form.\\r\\n74\\r\\nEstimating the Quantifiable Characteristics of Products, Events, or Information — Estimating sizes, distances, and quantities; or determining time, costs, resources, or materials needed to perform a work activity.\\r\\n73\\r\\nInterpreting the Meaning of Information for Others — Translating or explaining what information means and how it can be used.\\r\\n72\\r\\nJudging the Qualities of Things, Services, or People — Assessing the value, importance, or quality of things or people.\\r\\n71\\r\\nOrganizing, Planning, and Prioritizing Work — Developing specific goals and plans to prioritize, organize, and accomplish your work.\\r\\n71\\r\\nCoordinating the Work and Activities of Others — Getting members of a group to work together to accomplish tasks.\\r\\n68\\r\\nEvaluating Information to Determine Compliance with Standards — Using relevant information and individual judgment to determine whether events or processes comply with laws, regulations, or standards.\\r\\n67\\r\\nCommunicating with Persons Outside Organization — Communicating with people outside the organization, representing the organization to customers, the public, government, and other external sources. This information can be exchanged in person, in writing, or by telephone or e-mail.\\r\\n66\\r\\nEstablishing and Maintaining Interpersonal Relationships — Developing constructive and cooperative working relationships with others, and maintaining them over time.\\r\\n62\\r\\nScheduling Work and Activities — Scheduling events, programs, and activities, as well as the work of others.\\r\\n62\\r\\nProvide Consultation and Advice to Others — Providing guidance and expert advice to management or other groups on technical, systems-, or process-related topics.\\r\\n61\\r\\nMonitoring and Controlling Resources — Monitoring and controlling resources and overseeing the spending of money.\\r\\n60\\r\\nGuiding, Directing, and Motivating Subordinates — Providing guidance and direction to subordinates, including setting performance standards and monitoring performance.\\r\\n57\\r\\nInspecting Equipment, Structures, or Material — Inspecting equipment, structures, or materials to identify the cause of errors or other problems or defects.\\r\\n57\\r\\nControlling Machines and Processes — Using either control mechanisms or direct physical activity to operate machines or processes (not including computers or vehicles).\\r\\n56\\r\\nTraining and Teaching Others — Identifying the educational needs of others, developing formal educational or training programs or classes, and teaching or instructing others.\\r\\n48\\r\\nCoaching and Developing Others — Identifying the developmental needs of others and coaching, mentoring, or otherwise helping others to improve their knowledge or skills.\\r\\n47\\r\\nSelling or Influencing Others — Convincing others to buy merchandise/goods or to otherwise change their minds or actions.\\r\\n46\\r\\nResolving Conflicts and Negotiating with Others — Handling complaints, settling disputes, and resolving grievances and conflicts, or otherwise negotiating with others.\\r\\n45\\r\\nRepairing and Maintaining Electronic Equipment — Servicing, repairing, calibrating, regulating, fine-tuning, or testing machines, devices, and equipment that operate primarily on the basis of electrical or electronic (not mechanical) principles.\\r\\n45\\r\\nDrafting, Laying Out, and Specifying Technical Devices, Parts, and Equipment — Providing documentation, detailed instructions, drawings, or specifications to tell others about how devices, parts, equipment, or structures are to be fabricated, constructed, assembled, modified, maintained, or used.\\r\\n44\\r\\nPerforming General Physical Activities — Performing physical activities that require considerable use of your arms and legs and moving your whole body, such as climbing, lifting, balancing, walking, stooping, and handling of materials.\\r\\n40\\r\\nStaffing Organizational Units — Recruiting, interviewing, selecting, hiring, and promoting employees in an organization.\\r\\n39\\r\\nAssisting and Caring for Others — Providing personal assistance, medical attention, emotional support, or other personal care to others such as coworkers, customers, or patients.\\r\\n37\\r\\nPerforming Administrative Activities — Performing day-to-day administrative tasks such as maintaining information files and processing paperwork.\\r\\n35\\r\\nRepairing and Maintaining Mechanical Equipment — Servicing, repairing, adjusting, and testing machines, devices, moving parts, and equipment that operate primarily on the basis of mechanical (not electronic) principles.\\r\\n34\\r\\nHandling and Moving Objects — Using hands and arms in handling, installing, positioning, and moving materials, and manipulating things.\\r\\n      Nature of the Work\\r\\n(Abstract from Career Articles)\\r\\nArchitectural and Engineering Managers\\r\\nArchitectural and engineering managers plan, direct, and coordinate activities in architectural and engineering companies.\\r\\nRead More >>\\r\\n    Working Conditions\\r\\n(Abstract from Career Articles)\\r\\nArchitectural and Engineering Managers\\r\\nMost architectural and engineering managers work in offices, although some may also work in laboratories and industrial production plants or at construction sites. Most work full time, and about half worked more than 40 hours a week in 2014.\\r\\nRead More >>\\r\\n      << Previous Page Next Page >>\\r\\n    Source: MyPlan.com, LLC, 2019; includes information from the O*NET 20.3 database, 2016, and the Bureau of Labor Statistics, U.S. Department of Labor, Occupational Outlook Handbook, 2014-2024 Edition. O*NET™ is a trademark of the U.S. Department of Labor, Employment and Training Administration.  \\r\\n\\r\\n  Careers / Biofuels/Biodiesel Technology and Product Development Managers  \\r\\n        Job Requirements\\r\\nExperience: A considerable amount of work-related skill, knowledge, or experience is needed for these occupations. For example, an accountant must complete four years of college and work for several years in accounting to be considered qualified.\\r\\nEducation: Most of these occupations require a four-year bachelor's degree, but some do not.\\r\\nTraining: Employees in these occupations usually need several years of work-related experience, on-the-job training, and/or vocational training.\\r\\n  Top 5 Skills   Top 5 Abilities\\r\\nWriting — Communicating effectively in writing as appropriate for the needs of the audience.\\r\\nSpeaking — Talking to others to convey information effectively.\\r\\nReading Comprehension — Understanding written sentences and paragraphs in work related documents.\\r\\nCritical Thinking — Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems.\\r\\nSystems Analysis — Determining how a system should work and how changes in conditions, operations, and the environment will affect outcomes.\\r\\n  Oral Comprehension — The ability to listen to and understand information and ideas presented through spoken words and sentences.\\r\\nWritten Comprehension — The ability to read and understand information and ideas presented in writing.\\r\\nProblem Sensitivity — The ability to tell when something is wrong or is likely to go wrong. It does not involve solving the problem, only recognizing there is a problem.\\r\\nDeductive Reasoning — The ability to apply general rules to specific problems to produce answers that make sense.\\r\\nWritten Expression — The ability to communicate information and ideas in writing so others will understand.\\r\\n  Knowledge\\r\\nImportance Area of Knowledge\\r\\n77\\r\\nEnglish Language — Knowledge of the structure and content of the English language including the meaning and spelling of words, rules of composition, and grammar.\\r\\n76\\r\\nChemistry — Knowledge of the chemical composition, structure, and properties of substances and of the chemical processes and transformations that they undergo. This includes uses of chemicals and their interactions, danger signs, production techniques, and disposal methods.\\r\\n74\\r\\nEngineering and Technology — Knowledge of the practical application of engineering science and technology. This includes applying principles, techniques, procedures, and equipment to the design and production of various goods and services.\\r\\n64\\r\\nMathematics — Knowledge of arithmetic, algebra, geometry, calculus, statistics, and their applications.\\r\\n60\\r\\nProduction and Processing — Knowledge of raw materials, production processes, quality control, costs, and other techniques for maximizing the effective manufacture and distribution of goods.\\r\\n56\\r\\nComputers and Electronics — Knowledge of circuit boards, processors, chips, electronic equipment, and computer hardware and software, including applications and programming.\\r\\n55\\r\\nMechanical — Knowledge of machines and tools, including their designs, uses, repair, and maintenance.\\r\\n52\\r\\nAdministration and Management — Knowledge of business and management principles involved in strategic planning, resource allocation, human resources modeling, leadership technique, production methods, and coordination of people and resources.\\r\\n49\\r\\nCustomer and Personal Service — Knowledge of principles and processes for providing customer and personal services. This includes customer needs assessment, meeting quality standards for services, and evaluation of customer satisfaction.\\r\\n46\\r\\nPhysics — Knowledge and prediction of physical principles, laws, their interrelationships, and applications to understanding fluid, material, and atmospheric dynamics, and mechanical, electrical, atomic and sub- atomic structures and processes.\\r\\n  Training & Qualification\\r\\n(Abstract from Career Articles)\\r\\nArchitectural and Engineering Managers\\r\\nArchitectural and engineering managers typically need at least a bachelor's degree and considerable work experience as an architect or engineer.\\r\\nRead More >>\\r\\n      << Previous Page Next Page >>\\r\\n    Source: MyPlan.com, LLC, 2019; includes information from the O*NET 20.3 database, 2016, and the Bureau of Labor Statistics, U.S. Department of Labor, Occupational Outlook Handbook, 2014-2024 Edition. O*NET™ is a trademark of the U.S. Department of Labor, Employment and Training Administration.  \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents), documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m4udo5cllF6T"
      },
      "outputs": [],
      "source": [
        "system_prompt=\"\"\"\n",
        "You are a personal Q&A assistant. Your goal is to answer questions as\n",
        "accurately as possible based on the instructions and context provided.\n",
        "\"\"\"\n",
        "## Default format supportable by LLama2\n",
        "query_wrapper_prompt=SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki2Vf_pKZPb5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOSo_mxflKVg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `SChattoken` has been saved to C:\\Users\\ayush\\.cache\\huggingface\\stored_tokens\n",
            "Your token has been saved to C:\\Users\\ayush\\.cache\\huggingface\\token\n",
            "Login successful.\n",
            "The current active token is: `SChattoken`\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!huggingface-cli login --token (your token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LT9yZiX7lMfs"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGkfRsSrlgbu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Manually assign the token (replace with your actual token)\n",
        "token = \"xxx\"  # Replace 'xxx' with your real Hugging Face token\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=1024,\n",
        "    generate_kwargs={\"temperature\": 0.8, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"stabilityai/stablelm-zephyr-3b\",\n",
        "    model_name=\"stabilityai/stablelm-zephyr-3b\",\n",
        "    # device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # Explicitly set device\n",
        "    device_map=\"balanced\",  # Explicitly set device\n",
        "    model_kwargs={\"torch_dtype\": torch.float16, \"load_in_4bit\": True, 'token': token}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Nc5U3JnPqWZ7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-embeddings-langchain in c:\\users\\ayush\\anaconda3\\lib\\site-packages (0.3.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-embeddings-langchain) (0.12.30)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (3.10.5)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2.0.0)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2025.3.0)\n",
            "Requirement already satisfied: httpx in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (3.9.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (4.13.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (0.9.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.14.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.11.0)\n",
            "Requirement already satisfied: griffe in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.7.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (3.1.6)\n",
            "Requirement already satisfied: click in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (3.0.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (3.26.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (4.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.0.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-langchain) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-embeddings-langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bvuYtgBPzn7t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in c:\\users\\ayush\\anaconda3\\lib\\site-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.51)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.34)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.19)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "voN0hVRfzX-Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_7848\\1836198419.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "# from llama_index.core import ServiceContext\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "\n",
        "embed_model=LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BuNjt5fYzclp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zrZtUwet0WHn"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.settings import Settings\n",
        "\n",
        "Settings.chunk_size = 1024\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UtDpRSFX0WoJ"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "O2_VQlpH0icj"
      },
      "outputs": [],
      "source": [
        "query_engine=index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9QQDF-F-1BLD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2200 > 2048). Running this sequence through the model will result in indexing errors\n",
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " To calculate the basic salary of a data scientist based on the provided context, we need to find the average of the salaries for statisticians and computer and information research scientists, since they are close related jobs.\n",
            "\n",
            "From the context, we know that statisticians typically need at least a master's degree in statistics, mathematics, or another quantitative field, and computer and information research scientists require a graduate school degree. Both jobs require extensive skill, knowledge, and experience.\n",
            "\n",
            "According to the context, the Top 5 Skills for statisticians are: Mathematics, Reading Comprehension, Critical Thinking, Active Listening, and Inductive Reasoning. The Top 5 Skills for computer and information research scientists are: Complex Problem Solving, Systems Evaluation, Critical Thinking, Systems Analysis, and Judgment and Decision Making.\n",
            "\n",
            "Based on the information provided, we can't directly calculate the average salary. However, we can estimate the salary by looking at the average of the top skills for both jobs.\n",
            "\n",
            "For statisticians:\n",
            "Mathematics (100) - Reading Comprehension (31) - Critical Thinking (31) - Active Listening (16) - Inductive Reasoning (16) = 0\n",
            "\n",
            "For computer and information research scientists:\n",
            "Complex Problem Solving (90) - Systems Evaluation (64) - Critical Thinking (31) - Systems Analysis (24) - Judgment and Decision Making (24) = 0\n",
            "\n",
            "Since the sum of all skills for both jobs is 0, it means that the basic salary of a data scientist would be 0. However, this answer is not meaningful, as it represents an impossible situation.\n",
            "\n",
            "Please note that the provided context only gives an overview of the skills and requirements for these careers, and it doesn't provide actual salary data. To find a more accurate answer, one would need to access a reliable source with salary information for data scientists, such as a professional organization or a salary survey.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"What is the basic salary of a data scientist\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_Up9AR4ObR9K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Gradio in c:\\users\\ayush\\anaconda3\\lib\\site-packages (5.23.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (4.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (2.8.2)\n",
            "Requirement already satisfied: pydub in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.11.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (4.13.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from Gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from gradio-client==1.8.0->Gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from gradio-client==1.8.0->Gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->Gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->Gradio) (1.3.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->Gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->Gradio) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->Gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->Gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->Gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->Gradio) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->Gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->Gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->Gradio) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic>=2.0->Gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic>=2.0->Gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->Gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->Gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->Gradio) (13.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->Gradio) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->Gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->Gradio) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->Gradio) (2.15.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->Gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->Gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->Gradio) (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lxlSigZFoLbL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows after salary cleaning: 28989\n",
            "Unique experience levels found: Entry, Mid, Senior\n",
            "\n",
            "===== Model Evaluation Metrics =====\n",
            "\n",
            "Minimum :\n",
            "R² Score: 0.8781\n",
            "Mean Absolute Error: ₹32770.56\n",
            "Root Mean Squared Error: ₹177869.51\n",
            "Explained Variance Score: 0.8781\n",
            "\n",
            "Maximum :\n",
            "R² Score: 0.9991\n",
            "Mean Absolute Error: ₹62411.51\n",
            "Root Mean Squared Error: ₹279618.96\n",
            "Explained Variance Score: 0.9991\n",
            "Prediction error plot saved to model_evaluation_results/min_salary_prediction_20250411_013419.png\n",
            "Prediction error plot saved to model_evaluation_results/max_salary_prediction_20250411_013419.png\n",
            "Feature importance plot saved to model_evaluation_results/feature_importance_20250411_013419.png\n",
            "Precision matrix plot saved to model_evaluation_results/precision_matrix_20250411_013419.png\n",
            "Confusion matrices plot saved to model_evaluation_results/confusion_matrices_20250411_013419.png\n",
            "\n",
            "Metrics saved to model_evaluation_results/model_metrics_20250411_013419.csv\n",
            "Salary prediction model loaded successfully!\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from collections import deque\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "\n",
        "# Import salary utility functions\n",
        "from salary_utils import (\n",
        "    years_to_experience_level, extract_job_role_and_experience,\n",
        "    is_daily_salary_query, is_monthly_salary_query, is_salary_query\n",
        ")\n",
        "\n",
        "# Try to import the salary predictor model\n",
        "try:\n",
        "    from nlp_salary_predictor import NLPSalaryPredictor, parse_user_input\n",
        "    # Initialize the model\n",
        "    salary_model = NLPSalaryPredictor()\n",
        "    has_salary_model = True\n",
        "    print(\"Salary prediction model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not load salary prediction model: {e}\")\n",
        "    has_salary_model = False\n",
        "\n",
        "# Multi-Turn Memory\n",
        "conversation_history = deque(maxlen=5)\n",
        "\n",
        "# Configure headers to mimic browser behavior\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "}\n",
        "\n",
        "# ===== CHATBOT FUNCTIONS =====\n",
        "def chatbot(input_text):\n",
        "    \"\"\"Handles chatbot queries with multi-turn memory.\"\"\"\n",
        "    conversation_history.append(f\"👤 User: {input_text}\")\n",
        "    \n",
        "    # Check if this is a salary-related query\n",
        "    if is_salary_query(input_text):\n",
        "        try:\n",
        "            # If nlp_salary_predictor is available, use it\n",
        "            if has_salary_model:\n",
        "                job_role, experience_level = parse_user_input(input_text)\n",
        "            else:\n",
        "                # Use our internal implementation\n",
        "                job_role, experience_level = extract_job_role_and_experience(input_text)\n",
        "            \n",
        "            # Try to get a salary prediction\n",
        "            try:\n",
        "                if has_salary_model:\n",
        "                    prediction_result = salary_model.predict_salary(job_role, experience_level)\n",
        "                else:\n",
        "                    # Mock prediction if model isn't available\n",
        "                    prediction_result = {\n",
        "                        'job_role_matched': job_role,\n",
        "                        'experience_level_matched': experience_level,\n",
        "                        'min_salary': 500000 if \"entry\" in experience_level.lower() else (1000000 if \"mid\" in experience_level.lower() else 2000000),\n",
        "                        'max_salary': 1000000 if \"entry\" in experience_level.lower() else (2000000 if \"mid\" in experience_level.lower() else 3500000)\n",
        "                    }\n",
        "                \n",
        "                # Check if the user wants daily or monthly salary\n",
        "                is_daily = is_daily_salary_query(input_text)\n",
        "                is_monthly = is_monthly_salary_query(input_text)\n",
        "                \n",
        "                if is_daily:\n",
        "                    # Assume 260 working days per year (52 weeks × 5 days)\n",
        "                    min_salary = prediction_result['min_salary'] / 260\n",
        "                    max_salary = prediction_result['max_salary'] / 260\n",
        "                    period = \"daily\"\n",
        "                elif is_monthly:\n",
        "                    min_salary = prediction_result['min_salary'] / 12\n",
        "                    max_salary = prediction_result['max_salary'] / 12\n",
        "                    period = \"monthly\"\n",
        "                else:\n",
        "                    min_salary = prediction_result['min_salary']\n",
        "                    max_salary = prediction_result['max_salary']\n",
        "                    period = \"yearly\"\n",
        "                \n",
        "                # Format the response nicely\n",
        "                response = f\"Based on my analysis for {prediction_result['job_role_matched']} at {prediction_result['experience_level_matched']} level:\\n\"\n",
        "                response += f\"The {period} salary range is typically between ₹{min_salary:,.2f} and ₹{max_salary:,.2f}.\"\n",
        "                \n",
        "                # If we provided daily or monthly, also provide annual for reference\n",
        "                if is_daily or is_monthly:\n",
        "                    response += f\"\\nOn an annual basis, this would be ₹{prediction_result['min_salary']:,.2f} to ₹{prediction_result['max_salary']:,.2f}.\"\n",
        "            except Exception as e:\n",
        "                # If prediction fails, use query_engine\n",
        "                print(f\"Salary prediction failed: {e}, using query_engine\")\n",
        "                full_context = \"\\n\".join(conversation_history)\n",
        "                response = query_engine.query(full_context)\n",
        "        except Exception as e:\n",
        "            # If parsing fails, use query_engine\n",
        "            print(f\"Salary parsing failed: {e}, using query_engine\")\n",
        "            full_context = \"\\n\".join(conversation_history)\n",
        "    else:\n",
        "        # For non-salary queries, use the general query engine\n",
        "        full_context = \"\\n\".join(conversation_history)\n",
        "        try:\n",
        "            response = query_engine.query(full_context)  # Ensure query_engine is initialized\n",
        "        except Exception as e:\n",
        "            # Fallback if query_engine is not available\n",
        "            print(f\"Query engine error: {e}\")\n",
        "            response = f\"You said: {input_text}\"\n",
        "\n",
        "    conversation_history.append(f\"\\n🤖 Assistant: {response}\\n\")\n",
        "    \n",
        "    # Return formatted conversation with single newlines\n",
        "    return \"\\n\".join(conversation_history)\n",
        "\n",
        "def clear_chat():\n",
        "    \"\"\"Clears the conversation history.\"\"\"\n",
        "    conversation_history.clear()\n",
        "    return \"\"\n",
        "\n",
        "# ===== LINKEDIN JOB SEARCH FUNCTIONS =====\n",
        "def scrape_linkedin_jobs(query, location=\"\"):\n",
        "    \"\"\"Scrape LinkedIn job listings based on search query\"\"\"\n",
        "    base_url = \"https://www.linkedin.com/jobs/search/\"\n",
        "    params = {\n",
        "        \"keywords\": query,\n",
        "        \"location\": location,\n",
        "        \"position\": 1,\n",
        "        \"pageNum\": 0\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(base_url, params=params, headers=HEADERS)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        \n",
        "        jobs = []\n",
        "        job_listings = soup.find_all('div', class_='base-card')\n",
        "        \n",
        "        for job in job_listings[:10]:  # Limit to 10 results\n",
        "            title = job.find('h3', class_='base-search-card__title').text.strip()\n",
        "            company = job.find('a', class_='hidden-nested-link').text.strip()\n",
        "            job_location = job.find('span', class_='job-search-card__location').text.strip()\n",
        "            link = job.find('a', class_='base-card__full-link')['href']\n",
        "            \n",
        "            jobs.append({\n",
        "                'title': title,\n",
        "                'company': company,\n",
        "                'location': job_location,\n",
        "                'link': link.split('?')[0]  # Clean URL\n",
        "            })\n",
        "            \n",
        "            time.sleep(0.5)  # Be polite with requests\n",
        "            \n",
        "        return jobs\n",
        "    \n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def display_jobs(query, location):\n",
        "    # Validate query to ensure it's job-related\n",
        "    if not is_valid_job_query(query):\n",
        "        return \"<div style='color: #FF6B6B; background-color: rgba(255, 107, 107, 0.1); padding: 15px; border-radius: 10px; border-left: 4px solid #FF6B6B;'><strong>⚠️ Invalid Job Query:</strong> Please enter a valid job title, role, or industry. Examples: 'Software Engineer', 'Data Scientist', 'Marketing', 'Healthcare'.</div>\"\n",
        "    \n",
        "    jobs = scrape_linkedin_jobs(query, location)\n",
        "    \n",
        "    if isinstance(jobs, str):  # Error case\n",
        "        return f\"<div style='color: red'>{jobs}</div>\"\n",
        "    \n",
        "    if not jobs:\n",
        "        return \"<div style='color: orange'>No jobs found for this search.</div>\"\n",
        "    \n",
        "    html_output = f\"<h3>Found {len(jobs)} jobs:</h3>\"\n",
        "    for idx, job in enumerate(jobs, 1):\n",
        "        html_output += f\"\"\"\n",
        "        <div style='margin-bottom: 20px; border-bottom: 1px solid #ccc; padding-bottom: 10px;'>\n",
        "            <h4>{idx}. {job['title']}</h4>\n",
        "            <p><strong>Company:</strong> {job['company']}</p>\n",
        "            <p><strong>Location:</strong> {job['location']}</p>\n",
        "            <p><a href=\"{job['link']}\" target=\"_blank\">View Job</a></p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    return html_output\n",
        "\n",
        "def is_valid_job_query(query):\n",
        "    \"\"\"\n",
        "    Validate if the query appears to be job-related.\n",
        "    Returns True for valid job queries, False otherwise.\n",
        "    \"\"\"\n",
        "    if not query or len(query.strip()) < 2:\n",
        "        return False\n",
        "        \n",
        "    # Common job-related terms/prefixes/suffixes\n",
        "    job_related_terms = [\n",
        "        \"developer\", \"engineer\", \"manager\", \"assistant\", \"specialist\", \"analyst\", \n",
        "        \"designer\", \"consultant\", \"coordinator\", \"director\", \"technician\", \"representative\",\n",
        "        \"administrator\", \"supervisor\", \"officer\", \"programmer\", \"scientist\", \"associate\",\n",
        "        \"intern\", \"job\", \"career\", \"position\", \"role\", \"hiring\", \"recruitment\",\n",
        "        \"full-time\", \"part-time\", \"remote\", \"work\", \"employment\",\n",
        "        # Industries\n",
        "        \"tech\", \"it\", \"software\", \"health\", \"medical\", \"finance\", \"banking\", \"education\",\n",
        "        \"retail\", \"sales\", \"marketing\", \"hr\", \"legal\", \"media\", \"design\", \"construction\",\n",
        "        \"manufacturing\", \"engineering\", \"science\", \"research\", \"data\", \"ai\", \"ml\",\n",
        "        # Roles\n",
        "        \"ceo\", \"cto\", \"cfo\", \"vp\", \"head\", \"lead\", \"junior\", \"senior\", \"mid\", \"staff\"\n",
        "    ]\n",
        "    \n",
        "    query_lower = query.lower()\n",
        "    \n",
        "    # Check if any job-related term is in the query\n",
        "    for term in job_related_terms:\n",
        "        if term in query_lower or query_lower in term:\n",
        "            return True\n",
        "            \n",
        "    # If query is very long, likely not a job search\n",
        "    if len(query_lower) > 50:\n",
        "        return False\n",
        "        \n",
        "    # If query contains question marks or specific non-job phrases\n",
        "    if \"?\" in query or \"who is\" in query_lower or \"what is\" in query_lower or \"how to\" in query_lower:\n",
        "        return False\n",
        "        \n",
        "    # Default to allowing the query if we're not sure\n",
        "    return True\n",
        "\n",
        "# Custom CSS for Styling\n",
        "custom_css = \"\"\"\n",
        "/* Modern Gradient-based Color Scheme */\n",
        ":root {\n",
        "    --primary: #7C4DFF;    /* Deep purple */\n",
        "    --secondary: #2A2E45;  /* Navy blue */\n",
        "    --background: #1A1C28; /* Space black */\n",
        "    --accent: #FF6B6B;     /* Coral pink */\n",
        "    --text: #F0F0FF;       /* Soft lavender */\n",
        "}\n",
        "\n",
        "/* Base Styling with Larger Fonts */\n",
        "body {\n",
        "    font-size: 19px !important;\n",
        "    line-height: 1.7 !important;\n",
        "    background: linear-gradient(135deg, var(--background) 0%, #242736 100%);\n",
        "    font-family: 'Inter', system-ui, sans-serif;\n",
        "    color: var(--text) !important;\n",
        "}\n",
        "\n",
        "/* Text Elements Scaling */\n",
        "h1 { font-size: 2.8rem !important; }\n",
        "h2 { font-size: 2.2rem !important; }\n",
        "h3 { font-size: 1.9rem !important; }\n",
        "p { font-size: 1.1em !important; }\n",
        "\n",
        "/* Chat Interface */\n",
        ".gr-box {\n",
        "    background: rgba(42, 46, 69, 0.85) !important;\n",
        "    backdrop-filter: blur(12px);\n",
        "    border-radius: 18px;\n",
        "    border: 1px solid rgba(124, 77, 255, 0.25);\n",
        "    font-size: 1.15rem !important;\n",
        "}\n",
        "\n",
        "/* Reduced gap between buttons */\n",
        ".button-row {\n",
        "    gap: 5px !important;\n",
        "}\n",
        "\n",
        "/* Conversation text spacing */\n",
        ".gr-textbox span {\n",
        "    line-height: 1.4 !important;\n",
        "    margin-bottom: 0.3rem !important;\n",
        "}\n",
        "\n",
        "/* Chat display customization */\n",
        "#chat-display {\n",
        "    padding: 8px !important;\n",
        "    margin-bottom: 10px !important;\n",
        "}\n",
        "\n",
        "#chat-display textarea {\n",
        "    line-height: 1.3 !important;\n",
        "}\n",
        "\n",
        "/* Input Fields */\n",
        "input[type=\"text\"], textarea {\n",
        "    font-size: 1.2rem !important;\n",
        "    padding: 18px !important;\n",
        "    background: rgba(255, 255, 255, 0.08) !important;\n",
        "    border: 2px solid rgba(124, 77, 255, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        "button {\n",
        "    font-size: 1.25rem !important;\n",
        "    padding: 16px 28px !important;\n",
        "    background-image: linear-gradient(135deg, var(--primary) 0%, #906BFF 100%) !important;\n",
        "    border-radius: 14px !important;\n",
        "}\n",
        "\n",
        "button:hover {\n",
        "    transform: translateY(-2px) scale(1.02);\n",
        "    box-shadow: 0 10px 20px rgba(124, 77, 255, 0.25) !important;\n",
        "}\n",
        "\n",
        "/* Job Listings */\n",
        ".job-card {\n",
        "    background: linear-gradient(145deg, #2A2E45 0%, #1F2235 100%);\n",
        "    border-radius: 16px;\n",
        "    padding: 24px;\n",
        "    font-size: 1.1rem !important;\n",
        "}\n",
        "\n",
        ".job-card h4 {\n",
        "    font-size: 1.5rem !important;\n",
        "    background: linear-gradient(45deg, var(--primary), var(--accent));\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "}\n",
        "\n",
        "/* Chat History */\n",
        "#chat-history {\n",
        "    font-size: 1.2rem !important;\n",
        "    line-height: 1.8 !important;\n",
        "    padding: 24px !important;\n",
        "}\n",
        "\n",
        "/* Interactive Elements */\n",
        ".gr-textbox:focus, button:focus {\n",
        "    box-shadow: 0 0 0 4px rgba(124, 77, 255, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* Scrollbar */\n",
        "::-webkit-scrollbar {\n",
        "    width: 10px;\n",
        "    background: var(--secondary);\n",
        "}\n",
        "\n",
        "::-webkit-scrollbar-thumb {\n",
        "    background: linear-gradient(var(--primary), var(--accent));\n",
        "    border-radius: 6px;\n",
        "}\n",
        "\n",
        "/* Section Dividers */\n",
        ".section-divider {\n",
        "    height: 4px;\n",
        "    background: linear-gradient(90deg, transparent 0%, var(--primary) 50%, transparent 100%);\n",
        "    margin: 2.5rem 0;\n",
        "}\n",
        "\n",
        "/* Status Messages */\n",
        ".gr-label {\n",
        "    font-size: 1.3rem !important;\n",
        "    letter-spacing: 0.5px;\n",
        "}\n",
        "\n",
        "/* Responsive Scaling */\n",
        "@media (max-width: 768px) {\n",
        "    body { font-size: 17px !important; }\n",
        "    h1 { font-size: 2.2rem !important; }\n",
        "    button { font-size: 1.1rem !important; }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the combined Gradio interface\n",
        "with gr.Blocks(css=custom_css, title=\"AI Assistant with Job Search\") as demo:\n",
        "    gr.Markdown(\"# 🤖 **Career Guidance AI Chatbot **\", elem_id=\"title\")\n",
        "    \n",
        "    # Chatbot Section (Top)\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"### 💬 Chat with an intelligent assistant!\", elem_id=\"subtitle\")\n",
        "        \n",
        "        chatbox = gr.Textbox(label=\"Conversation History\", interactive=False, lines=12, elem_id=\"chat-display\")\n",
        "        user_input = gr.Textbox(lines=1, placeholder=\"Type your message...\", label=\"Your Message\")\n",
        "        \n",
        "        with gr.Row(elem_classes=[\"button-row\"]):\n",
        "            submit_btn = gr.Button(\"🚀 Send\")\n",
        "            clear_btn = gr.Button(\"🗑️ Clear Chat\")\n",
        "\n",
        "        submit_btn.click(fn=chatbot, inputs=user_input, outputs=chatbox)\n",
        "        user_input.submit(fn=chatbot, inputs=user_input, outputs=chatbox)\n",
        "        clear_btn.click(fn=clear_chat, outputs=chatbox)\n",
        "    \n",
        "    # Divider\n",
        "    gr.Markdown(\"---\", elem_id=\"divider\", elem_classes=[\"section-divider\"])\n",
        "    \n",
        "    # LinkedIn Job Search Section (Bottom)\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"## 🔍 LinkedIn Job Search\", elem_id=\"subtitle\")\n",
        "        gr.Markdown(\"Enter your job search query below:\")\n",
        "        \n",
        "        with gr.Row():\n",
        "            job_query = gr.Textbox(label=\"Job title or keywords\", placeholder=\"Software Engineer\")\n",
        "            job_location = gr.Textbox(label=\"Location (optional)\", placeholder=\"New York\")\n",
        "        \n",
        "        search_btn = gr.Button(\"🔍 Search Jobs\")\n",
        "        \n",
        "        job_output = gr.HTML()\n",
        "        \n",
        "        search_btn.click(\n",
        "            fn=display_jobs,\n",
        "            inputs=[job_query, job_location],\n",
        "            outputs=job_output,\n",
        "        )\n",
        "\n",
        "# Define prediction function for Salary Predictor UI\n",
        "def predict_salary_from_query(query):\n",
        "    if not query or query.strip() == \"\":\n",
        "        return \"Please enter a job role or query.\"\n",
        "    \n",
        "    try:\n",
        "        # Parse natural language input to extract job role and experience\n",
        "        if has_salary_model:\n",
        "            job_role, experience_level = parse_user_input(query)\n",
        "        else:\n",
        "            job_role, experience_level = extract_job_role_and_experience(query)\n",
        "        \n",
        "        parsed_info = f\"## Parsed Input\\n\"\n",
        "        parsed_info += f\"- Job Role: **{job_role}**\\n\"\n",
        "        parsed_info += f\"- Experience Level: **{experience_level if experience_level else 'Not specified (using Entry-Level)'}**\\n\\n\"\n",
        "        \n",
        "        # Get prediction\n",
        "        if has_salary_model:\n",
        "            result = salary_model.predict_salary(job_role, experience_level)\n",
        "        else:\n",
        "            # Mock prediction if model isn't available\n",
        "            result = {\n",
        "                'job_role_matched': job_role,\n",
        "                'experience_level_matched': experience_level,\n",
        "                'min_salary': 500000 if \"entry\" in str(experience_level).lower() else (1000000 if \"mid\" in str(experience_level).lower() else 2000000),\n",
        "                'max_salary': 1000000 if \"entry\" in str(experience_level).lower() else (2000000 if \"mid\" in str(experience_level).lower() else 3500000)\n",
        "            }\n",
        "        \n",
        "        if isinstance(result, dict):\n",
        "            # Check if the user wants specific salary period\n",
        "            is_monthly = is_monthly_salary_query(query)\n",
        "            is_daily = is_daily_salary_query(query)\n",
        "            \n",
        "            # Create detailed output\n",
        "            output = parsed_info\n",
        "            output += f\"## Matched To\\n\"\n",
        "            output += f\"- Job Role: **{result['job_role_matched']}**\\n\"\n",
        "            output += f\"- Experience Level: **{result['experience_level_matched']}**\\n\\n\"\n",
        "            \n",
        "            # Display salary in all formats\n",
        "            output += f\"## Annual Salary Range\\n\"\n",
        "            output += f\"- Annual Minimum: **₹{result['min_salary']:,.2f}**\\n\"\n",
        "            output += f\"- Annual Maximum: **₹{result['max_salary']:,.2f}**\\n\\n\"\n",
        "            \n",
        "            output += f\"## Monthly Salary Range\\n\"\n",
        "            output += f\"- Monthly Minimum: **₹{result['min_salary']/12:,.2f}**\\n\"\n",
        "            output += f\"- Monthly Maximum: **₹{result['max_salary']/12:,.2f}**\\n\\n\"\n",
        "            \n",
        "            # Assume 260 working days per year (52 weeks × 5 days)\n",
        "            output += f\"## Daily Salary Range\\n\"\n",
        "            output += f\"- Daily Minimum: **₹{result['min_salary']/260:,.2f}**\\n\"\n",
        "            output += f\"- Daily Maximum: **₹{result['max_salary']/260:,.2f}**\\n\"\n",
        "            \n",
        "            return output\n",
        "        else:\n",
        "            return parsed_info + str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Error processing your query: {str(e)}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:161: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
            "  return t.to(\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading documents from data/scraped...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5db5ec7b71204c8ea52000bfdb81ebbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing nodes:   0%|          | 0/1011 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63c91a1df94748abaaeeb376c4f1d654",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb489eed6e5c4689a7fda55bfff11a31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/1625 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import os\n",
        "# from pathlib import Path\n",
        "# import torch\n",
        "# import gradio as gr\n",
        "\n",
        "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "# from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "# from llama_index.core.storage import StorageContext\n",
        "# from llama_index.core.settings import Settings\n",
        "# from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
        "\n",
        "# # Prevent CUDA fragmentation\n",
        "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "\n",
        "# class CareerGuidanceRAG:\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         embedding_model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
        "#         llm_model_name=\"stabilityai/stablelm-zephyr-3b\",\n",
        "#         device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#     ):\n",
        "#         self.device = device\n",
        "\n",
        "#         # Define query wrapper prompt\n",
        "#         query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")\n",
        "\n",
        "#         # Initialize embedding model\n",
        "#         self.embedding_model = HuggingFaceEmbedding(\n",
        "#             model_name=embedding_model_name,\n",
        "#             device=self.device\n",
        "#         )\n",
        "\n",
        "#         # Initialize LLM with 4-bit quantization\n",
        "#         try:\n",
        "#             self.llm = HuggingFaceLLM(\n",
        "#                 model_name=llm_model_name,\n",
        "#                 tokenizer_name=llm_model_name,\n",
        "#                 context_window=4096,\n",
        "#                 max_new_tokens=512,\n",
        "#                 generate_kwargs={\"temperature\": 0.8, \"do_sample\": True},\n",
        "#                 system_prompt=\"\"\"\n",
        "#                    You are a Q&A assistant. Your goal is to answer questions as\n",
        "#                    accurately as possible based on the instructions and context provided.\n",
        "#                    \"\"\",\n",
        "#                 query_wrapper_prompt=query_wrapper_prompt,\n",
        "#                 device_map=\"auto\",\n",
        "#                 model_kwargs={\n",
        "#                     \"torch_dtype\": torch.float16,\n",
        "#                     \"load_in_4bit\": True\n",
        "#                 }\n",
        "#             )\n",
        "#         except RuntimeError:\n",
        "#             print(\"CUDA OOM! Falling back to CPU...\")\n",
        "#             self.device = \"cpu\"\n",
        "#             self.llm = HuggingFaceLLM(\n",
        "#                 model_name=llm_model_name,\n",
        "#                 tokenizer_name=llm_model_name,\n",
        "#                 context_window=4096,\n",
        "#                 max_new_tokens=512,\n",
        "#                 generate_kwargs={\"temperature\": 0.8, \"do_sample\": True},\n",
        "#                 system_prompt=\"\"\"\n",
        "#                 You are a Q&A assistant. Your goal is to answer questions as\n",
        "#                 accurately as possible based on the instructions and context provided.\n",
        "#                 \"\"\",\n",
        "#                 query_wrapper_prompt=query_wrapper_prompt,\n",
        "#                 device_map=\"auto\",\n",
        "#                 model_kwargs={\n",
        "#                     \"torch_dtype\": torch.float16,\n",
        "#                     \"load_in_4bit\": True\n",
        "#                 }\n",
        "#             )\n",
        "\n",
        "#         # Set up LlamaIndex settings\n",
        "#         Settings.chunk_size = 1024\n",
        "#         Settings.llm = self.llm\n",
        "#         Settings.embed_model = self.embedding_model\n",
        "\n",
        "#         self.storage_context = StorageContext.from_defaults()\n",
        "#         self.index = None\n",
        "\n",
        "#     def load_documents_from_folder(self, folder_path: str):\n",
        "#         print(f\"Loading documents from {folder_path}...\")\n",
        "#         folder_path = Path(folder_path)\n",
        "\n",
        "#         documents = SimpleDirectoryReader(\n",
        "#             input_dir=str(folder_path),\n",
        "#             recursive=True,\n",
        "#             exclude_hidden=True\n",
        "#         ).load_data()\n",
        "\n",
        "#         self.index = VectorStoreIndex.from_documents(\n",
        "#             documents,\n",
        "#             storage_context=self.storage_context,\n",
        "#             show_progress=True\n",
        "#         )\n",
        "\n",
        "#     def generate(self, query: str) -> str:\n",
        "#         if self.index is None:\n",
        "#             return \"Document index not initialized. Please upload documents first.\"\n",
        "\n",
        "#         query_engine = self.index.as_query_engine(\n",
        "#             similarity_top_k=5,\n",
        "#             # response_mode=\"tree_summarize\"\n",
        "#         )\n",
        "\n",
        "#         return str(query_engine.query(query))\n",
        "\n",
        "\n",
        "# # ==== GRADIO UI ====\n",
        "# rag = CareerGuidanceRAG()\n",
        "# rag.load_documents_from_folder(\"data/scraped\")  # Update this path as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows after salary cleaning: 28989\n",
            "Unique experience levels found: Entry, Mid, Senior\n",
            "\n",
            "===== Model Evaluation Metrics =====\n",
            "\n",
            "Minimum :\n",
            "R² Score: 0.8781\n",
            "Mean Absolute Error: ₹32770.56\n",
            "Root Mean Squared Error: ₹177869.51\n",
            "Explained Variance Score: 0.8781\n",
            "\n",
            "Maximum :\n",
            "R² Score: 0.9991\n",
            "Mean Absolute Error: ₹62411.51\n",
            "Root Mean Squared Error: ₹279618.96\n",
            "Explained Variance Score: 0.9991\n",
            "Prediction error plot saved to model_evaluation_results/min_salary_prediction_20250411_014330.png\n",
            "Prediction error plot saved to model_evaluation_results/max_salary_prediction_20250411_014330.png\n",
            "Feature importance plot saved to model_evaluation_results/feature_importance_20250411_014330.png\n",
            "Precision matrix plot saved to model_evaluation_results/precision_matrix_20250411_014330.png\n",
            "Confusion matrices plot saved to model_evaluation_results/confusion_matrices_20250411_014330.png\n",
            "\n",
            "Metrics saved to model_evaluation_results/model_metrics_20250411_014330.csv\n",
            "Salary prediction model loaded successfully!\n",
            "* Running on local URL:  http://127.0.0.1:7863\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from collections import deque\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "\n",
        "# Import salary utility functions\n",
        "from salary_utils import (\n",
        "    years_to_experience_level, extract_job_role_and_experience,\n",
        "    is_daily_salary_query, is_monthly_salary_query, is_salary_query\n",
        ")\n",
        "\n",
        "# Try to import the salary predictor model\n",
        "try:\n",
        "    from nlp_salary_predictor import NLPSalaryPredictor, parse_user_input\n",
        "    # Initialize the model\n",
        "    salary_model = NLPSalaryPredictor()\n",
        "    has_salary_model = True\n",
        "    print(\"Salary prediction model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not load salary prediction model: {e}\")\n",
        "    has_salary_model = False\n",
        "\n",
        "# Multi-Turn Memory\n",
        "conversation_history = deque(maxlen=5)\n",
        "\n",
        "# Configure headers to mimic browser behavior\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "}\n",
        "\n",
        "# ===== CHATBOT FUNCTIONS =====\n",
        "def chatbot(input_text):\n",
        "    \"\"\"Handles chatbot queries with multi-turn memory.\"\"\"\n",
        "    conversation_history.append(f\"👤 User: {input_text}\")\n",
        "    \n",
        "    # Check if this is a salary-related query\n",
        "    if is_salary_query(input_text):\n",
        "        try:\n",
        "            # If nlp_salary_predictor is available, use it\n",
        "            if has_salary_model:\n",
        "                job_role, experience_level = parse_user_input(input_text)\n",
        "            else:\n",
        "                # Use our internal implementation\n",
        "                job_role, experience_level = extract_job_role_and_experience(input_text)\n",
        "            \n",
        "            # Try to get a salary prediction\n",
        "            try:\n",
        "                if has_salary_model:\n",
        "                    prediction_result = salary_model.predict_salary(job_role, experience_level)\n",
        "                else:\n",
        "                    # Mock prediction if model isn't available\n",
        "                    prediction_result = {\n",
        "                        'job_role_matched': job_role,\n",
        "                        'experience_level_matched': experience_level,\n",
        "                        'min_salary': 500000 if \"entry\" in experience_level.lower() else (1000000 if \"mid\" in experience_level.lower() else 2000000),\n",
        "                        'max_salary': 1000000 if \"entry\" in experience_level.lower() else (2000000 if \"mid\" in experience_level.lower() else 3500000)\n",
        "                    }\n",
        "                \n",
        "                # Check if the user wants daily or monthly salary\n",
        "                is_daily = is_daily_salary_query(input_text)\n",
        "                is_monthly = is_monthly_salary_query(input_text)\n",
        "                \n",
        "                if is_daily:\n",
        "                    # Assume 260 working days per year (52 weeks × 5 days)\n",
        "                    min_salary = prediction_result['min_salary'] / 260\n",
        "                    max_salary = prediction_result['max_salary'] / 260\n",
        "                    period = \"daily\"\n",
        "                elif is_monthly:\n",
        "                    min_salary = prediction_result['min_salary'] / 12\n",
        "                    max_salary = prediction_result['max_salary'] / 12\n",
        "                    period = \"monthly\"\n",
        "                else:\n",
        "                    min_salary = prediction_result['min_salary']\n",
        "                    max_salary = prediction_result['max_salary']\n",
        "                    period = \"yearly\"\n",
        "                \n",
        "                # Format the response nicely\n",
        "                response = f\"Based on my analysis for {prediction_result['job_role_matched']} at {prediction_result['experience_level_matched']} level:\\n\"\n",
        "                response += f\"The {period} salary range is typically between ₹{min_salary:,.2f} and ₹{max_salary:,.2f}.\"\n",
        "                \n",
        "                # If we provided daily or monthly, also provide annual for reference\n",
        "                if is_daily or is_monthly:\n",
        "                    response += f\"\\nOn an annual basis, this would be ₹{prediction_result['min_salary']:,.2f} to ₹{prediction_result['max_salary']:,.2f}.\"\n",
        "            except Exception as e:\n",
        "                # If prediction fails, use query_engine\n",
        "                print(f\"Salary prediction failed: {e}, using query_engine\")\n",
        "                full_context = \"\\n\".join(conversation_history)\n",
        "                response = rag.generate(full_context)\n",
        "        except Exception as e:\n",
        "            # If parsing fails, use query_engine\n",
        "            print(f\"Salary parsing failed: {e}, using query_engine\")\n",
        "            full_context = \"\\n\".join(conversation_history)\n",
        "    else:\n",
        "        # For non-salary queries, use the general query engine\n",
        "        full_context = \"\\n\".join(conversation_history)\n",
        "        try:\n",
        "            response = rag.generate(full_context)  # Ensure query_engine is initialized\n",
        "        except Exception as e:\n",
        "            # Fallback if query_engine is not available\n",
        "            print(f\"Query engine error: {e}\")\n",
        "            response = f\"You said: {input_text}\"\n",
        "\n",
        "    conversation_history.append(f\"\\n🤖 Assistant: {response}\\n\")\n",
        "    \n",
        "    # Return formatted conversation with single newlines\n",
        "    return \"\\n\".join(conversation_history)\n",
        "\n",
        "def clear_chat():\n",
        "    \"\"\"Clears the conversation history.\"\"\"\n",
        "    conversation_history.clear()\n",
        "    return \"\"\n",
        "\n",
        "# ===== LINKEDIN JOB SEARCH FUNCTIONS =====\n",
        "def scrape_linkedin_jobs(query, location=\"\"):\n",
        "    \"\"\"Scrape LinkedIn job listings based on search query\"\"\"\n",
        "    base_url = \"https://www.linkedin.com/jobs/search/\"\n",
        "    params = {\n",
        "        \"keywords\": query,\n",
        "        \"location\": location,\n",
        "        \"position\": 1,\n",
        "        \"pageNum\": 0\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(base_url, params=params, headers=HEADERS)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        \n",
        "        jobs = []\n",
        "        job_listings = soup.find_all('div', class_='base-card')\n",
        "        \n",
        "        for job in job_listings[:10]:  # Limit to 10 results\n",
        "            title = job.find('h3', class_='base-search-card__title').text.strip()\n",
        "            company = job.find('a', class_='hidden-nested-link').text.strip()\n",
        "            job_location = job.find('span', class_='job-search-card__location').text.strip()\n",
        "            link = job.find('a', class_='base-card__full-link')['href']\n",
        "            \n",
        "            jobs.append({\n",
        "                'title': title,\n",
        "                'company': company,\n",
        "                'location': job_location,\n",
        "                'link': link.split('?')[0]  # Clean URL\n",
        "            })\n",
        "            \n",
        "            time.sleep(0.5)  # Be polite with requests\n",
        "            \n",
        "        return jobs\n",
        "    \n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def display_jobs(query, location):\n",
        "    # Validate query to ensure it's job-related\n",
        "    if not is_valid_job_query(query):\n",
        "        return \"<div style='color: #FF6B6B; background-color: rgba(255, 107, 107, 0.1); padding: 15px; border-radius: 10px; border-left: 4px solid #FF6B6B;'><strong>⚠️ Invalid Job Query:</strong> Please enter a valid job title, role, or industry. Examples: 'Software Engineer', 'Data Scientist', 'Marketing', 'Healthcare'.</div>\"\n",
        "    \n",
        "    jobs = scrape_linkedin_jobs(query, location)\n",
        "    \n",
        "    if isinstance(jobs, str):  # Error case\n",
        "        return f\"<div style='color: red'>{jobs}</div>\"\n",
        "    \n",
        "    if not jobs:\n",
        "        return \"<div style='color: orange'>No jobs found for this search.</div>\"\n",
        "    \n",
        "    html_output = f\"<h3>Found {len(jobs)} jobs:</h3>\"\n",
        "    for idx, job in enumerate(jobs, 1):\n",
        "        html_output += f\"\"\"\n",
        "        <div style='margin-bottom: 20px; border-bottom: 1px solid #ccc; padding-bottom: 10px;'>\n",
        "            <h4>{idx}. {job['title']}</h4>\n",
        "            <p><strong>Company:</strong> {job['company']}</p>\n",
        "            <p><strong>Location:</strong> {job['location']}</p>\n",
        "            <p><a href=\"{job['link']}\" target=\"_blank\">View Job</a></p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    return html_output\n",
        "\n",
        "def is_valid_job_query(query):\n",
        "    \"\"\"\n",
        "    Validate if the query appears to be job-related.\n",
        "    Returns True for valid job queries, False otherwise.\n",
        "    \"\"\"\n",
        "    if not query or len(query.strip()) < 2:\n",
        "        return False\n",
        "        \n",
        "    # Common job-related terms/prefixes/suffixes\n",
        "    job_related_terms = [\n",
        "        \"developer\", \"engineer\", \"manager\", \"assistant\", \"specialist\", \"analyst\", \n",
        "        \"designer\", \"consultant\", \"coordinator\", \"director\", \"technician\", \"representative\",\n",
        "        \"administrator\", \"supervisor\", \"officer\", \"programmer\", \"scientist\", \"associate\",\n",
        "        \"intern\", \"job\", \"career\", \"position\", \"role\", \"hiring\", \"recruitment\",\n",
        "        \"full-time\", \"part-time\", \"remote\", \"work\", \"employment\",\n",
        "        # Industries\n",
        "        \"tech\", \"it\", \"software\", \"health\", \"medical\", \"finance\", \"banking\", \"education\",\n",
        "        \"retail\", \"sales\", \"marketing\", \"hr\", \"legal\", \"media\", \"design\", \"construction\",\n",
        "        \"manufacturing\", \"engineering\", \"science\", \"research\", \"data\", \"ai\", \"ml\",\n",
        "        # Roles\n",
        "        \"ceo\", \"cto\", \"cfo\", \"vp\", \"head\", \"lead\", \"junior\", \"senior\", \"mid\", \"staff\"\n",
        "    ]\n",
        "    \n",
        "    query_lower = query.lower()\n",
        "    \n",
        "    # Check if any job-related term is in the query\n",
        "    for term in job_related_terms:\n",
        "        if term in query_lower or query_lower in term:\n",
        "            return True\n",
        "            \n",
        "    # If query is very long, likely not a job search\n",
        "    if len(query_lower) > 50:\n",
        "        return False\n",
        "        \n",
        "    # If query contains question marks or specific non-job phrases\n",
        "    if \"?\" in query or \"who is\" in query_lower or \"what is\" in query_lower or \"how to\" in query_lower:\n",
        "        return False\n",
        "        \n",
        "    # Default to allowing the query if we're not sure\n",
        "    return True\n",
        "\n",
        "# Custom CSS for Styling\n",
        "custom_css = \"\"\"\n",
        "/* Modern Gradient-based Color Scheme */\n",
        ":root {\n",
        "    --primary: #7C4DFF;    /* Deep purple */\n",
        "    --secondary: #2A2E45;  /* Navy blue */\n",
        "    --background: #1A1C28; /* Space black */\n",
        "    --accent: #FF6B6B;     /* Coral pink */\n",
        "    --text: #F0F0FF;       /* Soft lavender */\n",
        "}\n",
        "\n",
        "/* Base Styling with Larger Fonts */\n",
        "body {\n",
        "    font-size: 19px !important;\n",
        "    line-height: 1.7 !important;\n",
        "    background: linear-gradient(135deg, var(--background) 0%, #242736 100%);\n",
        "    font-family: 'Inter', system-ui, sans-serif;\n",
        "    color: var(--text) !important;\n",
        "}\n",
        "\n",
        "/* Text Elements Scaling */\n",
        "h1 { font-size: 2.8rem !important; }\n",
        "h2 { font-size: 2.2rem !important; }\n",
        "h3 { font-size: 1.9rem !important; }\n",
        "p { font-size: 1.1em !important; }\n",
        "\n",
        "/* Chat Interface */\n",
        ".gr-box {\n",
        "    background: rgba(42, 46, 69, 0.85) !important;\n",
        "    backdrop-filter: blur(12px);\n",
        "    border-radius: 18px;\n",
        "    border: 1px solid rgba(124, 77, 255, 0.25);\n",
        "    font-size: 1.15rem !important;\n",
        "}\n",
        "\n",
        "/* Reduced gap between buttons */\n",
        ".button-row {\n",
        "    gap: 5px !important;\n",
        "}\n",
        "\n",
        "/* Conversation text spacing */\n",
        ".gr-textbox span {\n",
        "    line-height: 1.4 !important;\n",
        "    margin-bottom: 0.3rem !important;\n",
        "}\n",
        "\n",
        "/* Chat display customization */\n",
        "#chat-display {\n",
        "    padding: 8px !important;\n",
        "    margin-bottom: 10px !important;\n",
        "}\n",
        "\n",
        "#chat-display textarea {\n",
        "    line-height: 1.3 !important;\n",
        "}\n",
        "\n",
        "/* Input Fields */\n",
        "input[type=\"text\"], textarea {\n",
        "    font-size: 1.2rem !important;\n",
        "    padding: 18px !important;\n",
        "    background: rgba(255, 255, 255, 0.08) !important;\n",
        "    border: 2px solid rgba(124, 77, 255, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        "button {\n",
        "    font-size: 1.25rem !important;\n",
        "    padding: 16px 28px !important;\n",
        "    background-image: linear-gradient(135deg, var(--primary) 0%, #906BFF 100%) !important;\n",
        "    border-radius: 14px !important;\n",
        "}\n",
        "\n",
        "button:hover {\n",
        "    transform: translateY(-2px) scale(1.02);\n",
        "    box-shadow: 0 10px 20px rgba(124, 77, 255, 0.25) !important;\n",
        "}\n",
        "\n",
        "/* Job Listings */\n",
        ".job-card {\n",
        "    background: linear-gradient(145deg, #2A2E45 0%, #1F2235 100%);\n",
        "    border-radius: 16px;\n",
        "    padding: 24px;\n",
        "    font-size: 1.1rem !important;\n",
        "}\n",
        "\n",
        ".job-card h4 {\n",
        "    font-size: 1.5rem !important;\n",
        "    background: linear-gradient(45deg, var(--primary), var(--accent));\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "}\n",
        "\n",
        "/* Chat History */\n",
        "#chat-history {\n",
        "    font-size: 1.2rem !important;\n",
        "    line-height: 1.8 !important;\n",
        "    padding: 24px !important;\n",
        "}\n",
        "\n",
        "/* Interactive Elements */\n",
        ".gr-textbox:focus, button:focus {\n",
        "    box-shadow: 0 0 0 4px rgba(124, 77, 255, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* Scrollbar */\n",
        "::-webkit-scrollbar {\n",
        "    width: 10px;\n",
        "    background: var(--secondary);\n",
        "}\n",
        "\n",
        "::-webkit-scrollbar-thumb {\n",
        "    background: linear-gradient(var(--primary), var(--accent));\n",
        "    border-radius: 6px;\n",
        "}\n",
        "\n",
        "/* Section Dividers */\n",
        ".section-divider {\n",
        "    height: 4px;\n",
        "    background: linear-gradient(90deg, transparent 0%, var(--primary) 50%, transparent 100%);\n",
        "    margin: 2.5rem 0;\n",
        "}\n",
        "\n",
        "/* Status Messages */\n",
        ".gr-label {\n",
        "    font-size: 1.3rem !important;\n",
        "    letter-spacing: 0.5px;\n",
        "}\n",
        "\n",
        "/* Responsive Scaling */\n",
        "@media (max-width: 768px) {\n",
        "    body { font-size: 17px !important; }\n",
        "    h1 { font-size: 2.2rem !important; }\n",
        "    button { font-size: 1.1rem !important; }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the combined Gradio interface\n",
        "with gr.Blocks(css=custom_css, title=\"AI Assistant with Job Search\") as demo:\n",
        "    gr.Markdown(\"# 🤖 **Career Guidance Chatbot **\", elem_id=\"title\")\n",
        "    \n",
        "    # Chatbot Section (Top)\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"### 💬 Chat with an intelligent assistant!\", elem_id=\"subtitle\")\n",
        "        \n",
        "        chatbox = gr.Textbox(label=\"Conversation History\", interactive=False, lines=12, elem_id=\"chat-display\")\n",
        "        user_input = gr.Textbox(lines=1, placeholder=\"Type your message...\", label=\"Your Message\")\n",
        "        \n",
        "        with gr.Row(elem_classes=[\"button-row\"]):\n",
        "            submit_btn = gr.Button(\"🚀 Send\")\n",
        "            clear_btn = gr.Button(\"🗑️ Clear Chat\")\n",
        "\n",
        "        submit_btn.click(fn=chatbot, inputs=user_input, outputs=chatbox)\n",
        "        user_input.submit(fn=chatbot, inputs=user_input, outputs=chatbox)\n",
        "        clear_btn.click(fn=clear_chat, outputs=chatbox)\n",
        "    \n",
        "    # Divider\n",
        "    gr.Markdown(\"---\", elem_id=\"divider\", elem_classes=[\"section-divider\"])\n",
        "    \n",
        "    # LinkedIn Job Search Section (Bottom)\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"## 🔍 LinkedIn Job Search\", elem_id=\"subtitle\")\n",
        "        gr.Markdown(\"Enter your job search query below:\")\n",
        "        \n",
        "        with gr.Row():\n",
        "            job_query = gr.Textbox(label=\"Job title or keywords\", placeholder=\"Software Engineer\")\n",
        "            job_location = gr.Textbox(label=\"Location (optional)\", placeholder=\"New York\")\n",
        "        \n",
        "        search_btn = gr.Button(\"🔍 Search Jobs\")\n",
        "        \n",
        "        job_output = gr.HTML()\n",
        "        \n",
        "        search_btn.click(\n",
        "            fn=display_jobs,\n",
        "            inputs=[job_query, job_location],\n",
        "            outputs=job_output,\n",
        "        )\n",
        "\n",
        "# Define prediction function for Salary Predictor UI\n",
        "def predict_salary_from_query(query):\n",
        "    if not query or query.strip() == \"\":\n",
        "        return \"Please enter a job role or query.\"\n",
        "    \n",
        "    try:\n",
        "        # Parse natural language input to extract job role and experience\n",
        "        if has_salary_model:\n",
        "            job_role, experience_level = parse_user_input(query)\n",
        "        else:\n",
        "            job_role, experience_level = extract_job_role_and_experience(query)\n",
        "        \n",
        "        parsed_info = f\"## Parsed Input\\n\"\n",
        "        parsed_info += f\"- Job Role: **{job_role}**\\n\"\n",
        "        parsed_info += f\"- Experience Level: **{experience_level if experience_level else 'Not specified (using Entry-Level)'}**\\n\\n\"\n",
        "        \n",
        "        # Get prediction\n",
        "        if has_salary_model:\n",
        "            result = salary_model.predict_salary(job_role, experience_level)\n",
        "        else:\n",
        "            # Mock prediction if model isn't available\n",
        "            result = {\n",
        "                'job_role_matched': job_role,\n",
        "                'experience_level_matched': experience_level,\n",
        "                'min_salary': 500000 if \"entry\" in str(experience_level).lower() else (1000000 if \"mid\" in str(experience_level).lower() else 2000000),\n",
        "                'max_salary': 1000000 if \"entry\" in str(experience_level).lower() else (2000000 if \"mid\" in str(experience_level).lower() else 3500000)\n",
        "            }\n",
        "        \n",
        "        if isinstance(result, dict):\n",
        "            # Check if the user wants specific salary period\n",
        "            is_monthly = is_monthly_salary_query(query)\n",
        "            is_daily = is_daily_salary_query(query)\n",
        "            \n",
        "            # Create detailed output\n",
        "            output = parsed_info\n",
        "            output += f\"## Matched To\\n\"\n",
        "            output += f\"- Job Role: **{result['job_role_matched']}**\\n\"\n",
        "            output += f\"- Experience Level: **{result['experience_level_matched']}**\\n\\n\"\n",
        "            \n",
        "            # Display salary in all formats\n",
        "            output += f\"## Annual Salary Range\\n\"\n",
        "            output += f\"- Annual Minimum: **₹{result['min_salary']:,.2f}**\\n\"\n",
        "            output += f\"- Annual Maximum: **₹{result['max_salary']:,.2f}**\\n\\n\"\n",
        "            \n",
        "            output += f\"## Monthly Salary Range\\n\"\n",
        "            output += f\"- Monthly Minimum: **₹{result['min_salary']/12:,.2f}**\\n\"\n",
        "            output += f\"- Monthly Maximum: **₹{result['max_salary']/12:,.2f}**\\n\\n\"\n",
        "            \n",
        "            # Assume 260 working days per year (52 weeks × 5 days)\n",
        "            output += f\"## Daily Salary Range\\n\"\n",
        "            output += f\"- Daily Minimum: **₹{result['min_salary']/260:,.2f}**\\n\"\n",
        "            output += f\"- Daily Maximum: **₹{result['max_salary']/260:,.2f}**\\n\"\n",
        "            \n",
        "            return output\n",
        "        else:\n",
        "            return parsed_info + str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Error processing your query: {str(e)}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
